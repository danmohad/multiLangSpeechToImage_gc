{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eface84a",
   "metadata": {},
   "source": [
    "# Speech-to-Image Using Google Cloud\n",
    "\n",
    "- Speech is recorded directly in the notebook\n",
    "- Recording is uploaded to Google Cloud Storate (GCS)\n",
    "- Google Speech-to-Text API to transcribe the recording from the specified lang & loc combination\n",
    "- Google Translate API to translate into English\n",
    "- DeepAI's _stable-diffusion_ to generate images\n",
    "- Save the desired image\n",
    "\n",
    "\n",
    "- D. Mohaddes\n",
    "- October 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ad9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spoken language\n",
    "lang = \"en\" # \"de\"\n",
    "loc  = \"US\" # \"DE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14027156",
   "metadata": {},
   "source": [
    "## Get audio from microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b138c91-d8d3-40f1-b487-108e6b781ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "import torchaudio\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb3e6b-3f55-42bc-b4b6-25ffecf38226",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275acd7-7385-4a28-a32a-ee400b90ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recording.webm', 'wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "!ffmpeg -i recording.webm -ac 1 -f flac voice_file.flac -y -hide_banner -loglevel panic\n",
    "# sig, sr = torchaudio.load(\"voice_file.flac\")\n",
    "# Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b167463",
   "metadata": {},
   "source": [
    "## Upload to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ./voice_file.flac gs://speech_to_image_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12326c",
   "metadata": {},
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1 as speech\n",
    "\n",
    "import IPython\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env GOOGLE_APPLICATION_CREDENTIALS=/Users/danmohad/key.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code = lang + \"_\" + loc\n",
    "audio_uri = \"gs://speech_to_image_data/voice_file.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79171903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(config, audio):\n",
    "    client = speech.SpeechClient()\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    print_sentences(response)\n",
    "    return response.results[0].alternatives[0].transcript\n",
    "\n",
    "\n",
    "def print_sentences(response):\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        confidence = best_alternative.confidence\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Transcript: {transcript}\")\n",
    "        print(f\"Confidence: {confidence:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c29c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    language_code=lang_code,\n",
    "    enable_automatic_punctuation=True,\n",
    "    enable_word_time_offsets=True,\n",
    ")\n",
    "audio = dict(uri=audio_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = speech_to_text(config, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dca1f1",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(target, text):\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    import six\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, source_language=lang, target_language=target)\n",
    "\n",
    "    print(u\"Text: {}\".format(result[\"input\"]))\n",
    "    print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    return result[\"translatedText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tr = translate_text(\"en\", txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62d2e7",
   "metadata": {},
   "source": [
    "## Generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(\n",
    "    #\"https://api.deepai.org/api/text2img\",\n",
    "    \"https://api.deepai.org/api/stable-diffusion\",\n",
    "    data={\n",
    "        'text': txt_tr,\n",
    "    },\n",
    "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(urllib.request.urlopen(r.json()['output_url']))\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 3\n",
    "\n",
    "w, h = im.size\n",
    "if choice == 0:\n",
    "    im1 = im.crop((0, 0, int(w/2), int(h/2)))\n",
    "elif choice == 1:\n",
    "    im1 = im.crop((int(w/2), 0, int(w), int(h/2)))\n",
    "elif choice == 2:\n",
    "    im1 = im.crop((0, int(h/2), int(w/2), int(h)))\n",
    "elif choice == 3:\n",
    "    im1 = im.crop((int(w/2), int(h/2), int(w), int(h)))\n",
    "\n",
    "display(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8531a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
